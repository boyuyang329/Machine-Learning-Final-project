{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd736741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from statistics import mode\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677eff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file \n",
    "df = pd.read_csv('/Users/yangboyu/Downloads/wine+quality/winequality-red.csv', sep=';')\n",
    "\n",
    "df\n",
    "\n",
    "# Check the DataFrame\n",
    "\n",
    "# # Select all columns except the last one as features (X)\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "# # Select the last column as the target variable (y)\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# print(X)\n",
    "# print(y)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6deb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and testing  20% for testing and 80% for training \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3544482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_model(X_train, y_train, X_test, y_test):\n",
    "   \n",
    "\n",
    "    # Assigning binary labels: 1 for quality=5 and 0 for other qualities\n",
    "    y_train_binary = (y_train == 5)\n",
    "    y_test_binary = (y_test == 5)\n",
    "    # WE have use one vs rest method in the perceptron model. We use quality 5 vs the rest of the quality\n",
    "    \n",
    "    perceptron = Perceptron()\n",
    "\n",
    "    # Train the model sequentially\n",
    "    perceptron.fit(X_train, y_train_binary)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = perceptron.predict(X_test)\n",
    "    \n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2130d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardized the data (不确定要不要，可以到时候再加上去)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9864c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN \n",
    "# Initialize the MLP classifier with custom activation function for hidden layers\n",
    "# batch_size ='auto' 就是 sequential training \n",
    "\n",
    "def train_ann_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Initialize the MLP classifier with specified hyperparameters\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(100),  # Number of neurons in the hidden layer\n",
    "        activation='logistic',  # Activation function for the hidden layer\n",
    "        max_iter=1000,  # Maximum number of iterations (epochs)\n",
    "        batch_size='auto',  # Batch size for training\n",
    "        random_state=42  # Random state for reproducibility\n",
    "    )\n",
    "\n",
    "    ann_start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # End the timer\n",
    "    ann_end_time = time.time()\n",
    "\n",
    "    # Calculate the training time\n",
    "    ann_training_time = ann_end_time - ann_start_time\n",
    "    \n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "    \n",
    "    return accuracy_mlp, ann_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de410f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 0.5625\n",
      "ANN Training Time: 0.30812597274780273 seconds\n"
     ]
    }
   ],
   "source": [
    "accuracy_mlp, training_time = train_ann_model(X_train, y_train, X_test, y_test)\n",
    "print(\"ANN Accuracy:\", accuracy_mlp)\n",
    "print(\"ANN Training Time:\", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN corss validation \n",
    "def train_anncv_model(X_train, y_train) :\n",
    "    \n",
    "        mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(100,),  # Number of neurons in the hidden layer\n",
    "        activation='logistic',  # Activation function for the hidden layer\n",
    "        max_iter=1000,  # Maximum number of iterations (epochs)\n",
    "        batch_size='auto',  # Batch size for training\n",
    "        random_state=42,  # Random state for reproducibility\n",
    "        learning_rate='constant',\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "        cv_scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "\n",
    "    # Calculate the mean accuracy of cross-validation scores\n",
    "        cv_accuracy = cv_scores.mean()\n",
    "    \n",
    "        return cv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60ac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa1f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree \n",
    "def train_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        criterion='entropy',  # Split criterion: 'entropy' for information gain\n",
    "        max_depth=100,  # Maximum depth of the tree\n",
    "        min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "        min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node\n",
    "        max_features=100,  # Number of features to consider when looking for the best split\n",
    "        random_state=42  # Random state for reproducibility\n",
    "    )    \n",
    "\n",
    "    # Initialize the Decision Tree classifier\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    dc_start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    # End the timer\n",
    "    dc_end_time = time.time()\n",
    "\n",
    "    # Calculate the training time\n",
    "    dc_training_time = dc_end_time - dc_start_time\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, dc_training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cc2e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.559375\n",
      "Decision Tree Training Time: 0.01784205436706543 seconds\n"
     ]
    }
   ],
   "source": [
    "accuracy3, dc_time = train_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy3)\n",
    "print(\"Decision Tree Training Time:\", dc_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd139ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree_cv(X_train, y_train):\n",
    "\n",
    "    # Initialize the Decision Tree classifier with specified hyperparameters\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        criterion='entropy',  # Split criterion: 'entropy' for information gain\n",
    "        max_depth=100,  # Maximum depth of the tree\n",
    "        min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "        min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node\n",
    "        max_features=100,  # Number of features to consider when looking for the best split\n",
    "        random_state=42  # Random state for reproducibility\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(decision_tree, X_train, y_train, cv=5)\n",
    "\n",
    "    # Calculate the mean accuracy of cross-validation scores\n",
    "    cv_accuracy = cv_scores.mean()\n",
    "    \n",
    "    return cv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ba0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest \n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Initialize the Random Forest classifier with specified hyperparameters\n",
    "    random_forest = RandomForestClassifier(\n",
    "        n_estimators=100,  # Number of trees in the forest\n",
    "        criterion='entropy',  # Split criterion: 'gini' for Gini impurity or 'entropy' for information gain\n",
    "        max_depth=None,  # Maximum depth of the trees\n",
    "        min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "        min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node\n",
    "        max_features=None,  # Number of features to consider when looking for the best split\n",
    "        random_state=42,  # Random state for reproducibility     \n",
    "    )\n",
    "\n",
    "    # Start the timer\n",
    "    rf_start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    random_forest.fit(X_train, y_train)\n",
    "\n",
    "    # End the timer\n",
    "    rf_end_time = time.time()\n",
    "\n",
    "    # Calculate the training time\n",
    "    rf_training_time = rf_end_time - rf_start_time\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, rf_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c869e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.640625\n",
      "Random Forest Training Time: 0.5135889053344727 seconds\n"
     ]
    }
   ],
   "source": [
    "accuracy4, rf_time = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy4)\n",
    "print(\"Random Forest Training Time:\", rf_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "213f0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_cv(X_train, y_train):\n",
    "    \n",
    "    # Initialize the Random Forest classifier with specified hyperparameters\n",
    "    random_forest = RandomForestClassifier(\n",
    "        n_estimators=100,  # Number of trees in the forest\n",
    "        criterion='entropy',  # Split criterion: 'gini' for Gini impurity or 'entropy' for information gain\n",
    "        max_depth=None,  # Maximum depth of the trees\n",
    "        min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "        min_samples_leaf=1,  # Minimum number of samples required to be at a leaf node\n",
    "        max_features=None,  # Number of features to consider when looking for the best split\n",
    "        random_state=42,  # Random state for reproducibility     \n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(random_forest, X_train, y_train, cv=5)\n",
    "\n",
    "    # Calculate the mean accuracy of cross-validation scores\n",
    "    cv_accuracy = cv_scores.mean()\n",
    "    \n",
    "    return cv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58002483",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4, time = train_random_forest(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d5e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 0.5625\n",
      "ANN Training Time: 0.30739307403564453 seconds\n",
      "ANN corss validation accuracy: 0.5966023284313725\n",
      "Decision Tree Accuracy: 0.559375\n",
      "Decision Tree Training Time: 0.011275053024291992 seconds\n",
      "Decision Tree cross validation Accuracy: 0.5950428921568627\n",
      "Random Forest Accuracy: 0.640625\n",
      "Random Forest Training Time: 0.5444803237915039 seconds\n",
      "Random Forest cross validation Accuracy: 0.6755729166666666\n"
     ]
    }
   ],
   "source": [
    "#Call the function\n",
    "# accuracy = train_perceptron_model(X_train, y_train, X_test, y_test)\n",
    "# print(\"Perceptron Accuracy:\", accuracy)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "accuracy_mlp, training_time = train_ann_model(X_train, y_train, X_test, y_test)\n",
    "print(\"ANN Accuracy:\", accuracy_mlp)\n",
    "print(\"ANN Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "accuracy2=train_anncv_model(X_train, y_train)\n",
    "print(\"ANN corss validation accuracy:\", accuracy2)\n",
    "\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "accuracy3, dc_time = train_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy3)\n",
    "print(\"Decision Tree Training Time:\", dc_time, \"seconds\")\n",
    "\n",
    "accuracy3 = train_decision_tree_cv(X_train, y_train)\n",
    "print(\"Decision Tree cross validation Accuracy:\", accuracy3)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "accuracy4, rf_time = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy4)\n",
    "print(\"Random Forest Training Time:\", rf_time, \"seconds\")\n",
    "\n",
    "accuracy4 = train_random_forest_cv(X_train, y_train)\n",
    "print(\"Random Forest cross validation Accuracy:\", accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d3c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangboyu/anaconda3/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x16b162590>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x='quality',data=df,kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training time for each of the model \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
